<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training a Simple LSTM · Lux</title><script data-outdated-warner src="../../../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../../../assets/documenter.js"></script><script src="../../../../../siteinfo.js"></script><script src="../../../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../../../assets/themeswap.js"></script><link href="../../../../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../../../../">Lux</a></span></div><form class="docs-search" action="../../../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../../../">Lux: Explicitly Parameterized Neural Networks</a></li><li><span class="tocitem">Introduction</span><ul><li><a class="tocitem" href="../../../../../introduction/overview/">All about Lux</a></li><li><a class="tocitem" href="../../../../../introduction/ecosystem/">Ecosystem</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox" checked/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Beginner</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../Basics/main/">Julia &amp; Lux for the Uninitiated</a></li><li class="is-active"><a class="tocitem" href>Training a Simple LSTM</a><ul class="internal"><li><a class="tocitem" href="#Package-Imports"><span>Package Imports</span></a></li><li><a class="tocitem" href="#Dataset"><span>Dataset</span></a></li><li><a class="tocitem" href="#Creating-a-Classifier"><span>Creating a Classifier</span></a></li><li><a class="tocitem" href="#Defining-Accuracy,-Loss-and-Optimiser"><span>Defining Accuracy, Loss and Optimiser</span></a></li><li><a class="tocitem" href="#Training-the-Model"><span>Training the Model</span></a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Intermediate</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../intermediate/NeuralODE/main/">MNIST NeuralODE Classification</a></li><li><a class="tocitem" href="../../../intermediate/BayesianNN/main/">Bayesian Neural Network</a></li></ul></li><li><span class="tocitem">Advanced</span></li><li><a class="tocitem" href="../../../../">Additional Examples</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../../../../../api/layers/">Layers</a></li><li><a class="tocitem" href="../../../../../api/functional/">Functional</a></li><li><a class="tocitem" href="../../../../../api/core/">Core</a></li><li><a class="tocitem" href="../../../../../api/utilities/">Utilities</a></li></ul></li><li><span class="tocitem">Design Docs</span><ul><li><a class="tocitem" href="../../../../../design/recurrent/">Recurrent Neural Networks</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li><a class="is-disabled">Beginner</a></li><li class="is-active"><a href>Training a Simple LSTM</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Training a Simple LSTM</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/avik-pal/Lux.jl/blob/main/examples/SimpleRNN/main.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Training-a-Simple-LSTM"><a class="docs-heading-anchor" href="#Training-a-Simple-LSTM">Training a Simple LSTM</a><a id="Training-a-Simple-LSTM-1"></a><a class="docs-heading-anchor-permalink" href="#Training-a-Simple-LSTM" title="Permalink"></a></h1><p>In this tutorial we will go over using a recurrent neural network to classify clockwise and anticlockwise spirals. By the end of this tutorial you will be able to:</p><ol><li>Create custom Lux models</li><li>Become familiar with the Lux recurrent neural network API</li><li>Training using Optimisers.jl and Zygote.jl</li></ol><h2 id="Package-Imports"><a class="docs-heading-anchor" href="#Package-Imports">Package Imports</a><a id="Package-Imports-1"></a><a class="docs-heading-anchor-permalink" href="#Package-Imports" title="Permalink"></a></h2><pre><code class="language-julia hljs">using Lux
using MLUtils, Optimisers, Zygote, NNlib, Random, Statistics</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">  Activating project at `~/work/Lux.jl/Lux.jl/examples`</code></pre><h2 id="Dataset"><a class="docs-heading-anchor" href="#Dataset">Dataset</a><a id="Dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Dataset" title="Permalink"></a></h2><p>We will use MLUtils to generate 500 (noisy) clockwise and 500 (noisy) anticlockwise spirals. Using this data we will create a <code>MLUtils.DataLoader</code>. Our dataloader will give us sequences of size 2 × seq<em>len × batch</em>size and we need to predict a binary value whether the sequence is clockwise or anticlockwise</p><pre><code class="language-julia hljs">function get_dataloaders(; dataset_size=1000, sequence_length=50)
    # Create the spirals
    data = [MLUtils.Datasets.make_spiral(sequence_length) for _ in 1:dataset_size]
    # Get the labels
    labels = vcat(repeat([0.0f0], dataset_size ÷ 2), repeat([1.0f0], dataset_size ÷ 2))
    clockwise_spirals = [reshape(d[1][:, 1:sequence_length], :, sequence_length, 1) for d in data[1:(dataset_size ÷ 2)]]
    anticlockwise_spirals = [
        reshape(d[1][:, (sequence_length + 1):end], :, sequence_length, 1) for d in data[((dataset_size ÷ 2) + 1):end]
    ]
    x_data = Float32.(cat(clockwise_spirals..., anticlockwise_spirals...; dims=3))
    # Split the dataset
    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)
    # Create DataLoaders
    return (
        # Use DataLoader to automatically minibatch and shuffle the data
        DataLoader(collect.((x_train, y_train)); batchsize=128, shuffle=true),
        # Don&#39;t shuffle the validation data
        DataLoader(collect.((x_val, y_val)); batchsize=128, shuffle=false),
    )
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">get_dataloaders (generic function with 1 method)</code></pre><h2 id="Creating-a-Classifier"><a class="docs-heading-anchor" href="#Creating-a-Classifier">Creating a Classifier</a><a id="Creating-a-Classifier-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-a-Classifier" title="Permalink"></a></h2><p>We will be extending the <code>Lux.AbstractExplicitContainerLayer</code> type for our custom model since it will contain a lstm block and a classifier head.</p><p>We pass the fieldnames <code>lstm_cell</code> and <code>classifier</code> to the type to ensure that the parameters and states are automatically populated and we don&#39;t have to define <a href="../../../../../api/core/#Lux.initialparameters"><code>Lux.initialparameters</code></a> and <a href="../../../../../api/core/#Lux.initialstates"><code>Lux.initialstates</code></a>.</p><pre><code class="language-julia hljs">struct SpiralClassifier{L,C} &lt;: Lux.AbstractExplicitContainerLayer{(:lstm_cell, :classifier)}
    lstm_cell::L
    classifier::C
end</code></pre><p>We won&#39;t define the model from scratch but rather use the <a href="../../../../../api/layers/#Lux.LSTMCell"><code>Lux.LSTMCell</code></a> and <a href="../../../../../api/layers/#Lux.Dense"><code>Lux.Dense</code></a></p><pre><code class="language-julia hljs">function SpiralClassifier(in_dims, hidden_dims, out_dims)
    return SpiralClassifier(LSTMCell(in_dims =&gt; hidden_dims), Dense(hidden_dims =&gt; out_dims, sigmoid))
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Main.SpiralClassifier</code></pre><p>Now we need to define the behavior of the Classifier when it is invoked</p><pre><code class="language-julia hljs">function (s::SpiralClassifier)(x::AbstractArray{T,3}, ps::NamedTuple, st::NamedTuple) where {T}
    # First we will have to run the sequence through the LSTM Cell
    # The first call to LSTM Cell will create the initial hidden state
    # See that the parameters and states are automatically populated into a field called `lstm_cell`
    # We use `view(x, :, 1, :)` to get the first element in the sequence without copying it
    (h, c), st_lstm = s.lstm_cell(view(x, :, 1, :), ps.lstm_cell, st.lstm_cell)
    # Now that we have the hidden state we will pass the input and hidden state jointly
    for i in 1:size(x, 2)
        (h, c), st_lstm = s.lstm_cell((view(x, :, i, :), h, c), ps.lstm_cell, st_lstm)
    end
    # After running through the sequence we will pass the output through the classifier
    y, st_classifier = s.classifier(h, ps.classifier, st.classifier)
    # Finally remember to create the updated state
    st = merge(st, (classifier=st_classifier, lstm_cell=st_lstm))
    return vec(y), st
end</code></pre><h2 id="Defining-Accuracy,-Loss-and-Optimiser"><a class="docs-heading-anchor" href="#Defining-Accuracy,-Loss-and-Optimiser">Defining Accuracy, Loss and Optimiser</a><a id="Defining-Accuracy,-Loss-and-Optimiser-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-Accuracy,-Loss-and-Optimiser" title="Permalink"></a></h2><p>Now let&#39;s define the binarycrossentropy loss. Typically it is recommended to use <code>logitbinarycrossentropy</code> since it is more numerically stable, but for the sake of simplicity we will use <code>binarycrossentropy</code></p><pre><code class="language-julia hljs">function xlogy(x, y)
    result = x * log(y)
    return ifelse(iszero(x), zero(result), result)
end

function binarycrossentropy(y_pred, y_true)
    y_pred = y_pred .+ eps(eltype(y_pred))
    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))
end

function compute_loss(x, y, model, ps, st)
    y_pred, st = model(x, ps, st)
    return binarycrossentropy(y_pred, y), y_pred, st
end

matches(y_pred, y_true) = sum((y_pred .&gt; 0.5) .== y_true)
accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">accuracy (generic function with 1 method)</code></pre><p>Finally lets create an optimiser given the model parameters</p><pre><code class="language-julia hljs">function create_optimiser(ps)
    opt = Optimisers.ADAM(0.01f0)
    return Optimisers.setup(opt, ps)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">create_optimiser (generic function with 1 method)</code></pre><h2 id="Training-the-Model"><a class="docs-heading-anchor" href="#Training-the-Model">Training the Model</a><a id="Training-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Training-the-Model" title="Permalink"></a></h2><pre><code class="language-julia hljs">function main()
    # Get the dataloaders
    (train_loader, val_loader) = get_dataloaders()

    # Create the model
    model = SpiralClassifier(2, 8, 1)
    rng = Random.default_rng()
    Random.seed!(rng, 0)
    ps, st = Lux.setup(rng, model)

    # Create the optimiser
    opt_state = create_optimiser(ps)

    for epoch in 1:25
        # Train the model
        for (x, y) in train_loader
            (loss, y_pred, st), back = pullback(p -&gt; compute_loss(x, y, model, p, st), ps)
            gs = back((one(loss), nothing, nothing))[1]
            opt_state, ps = Optimisers.update(opt_state, ps, gs)

            println(&quot;Epoch [$epoch]: Loss $loss&quot;)
        end

        # Validate the model
        st_ = Lux.testmode(st)
        for (x, y) in val_loader
            (loss, y_pred, st_) = compute_loss(x, y, model, ps, st_)
            acc = accuracy(y_pred, y)
            println(&quot;Validation: Loss $loss Accuracy $acc&quot;)
        end
    end
end

main()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch [1]: Loss 0.5634405
Epoch [1]: Loss 0.5134852
Epoch [1]: Loss 0.4689028
Epoch [1]: Loss 0.44403377
Epoch [1]: Loss 0.4340855
Epoch [1]: Loss 0.40325302
Epoch [1]: Loss 0.40058252
Validation: Loss 0.35908693 Accuracy 1.0
Validation: Loss 0.35410467 Accuracy 1.0
Epoch [2]: Loss 0.37055323
Epoch [2]: Loss 0.3513467
Epoch [2]: Loss 0.33370492
Epoch [2]: Loss 0.3188854
Epoch [2]: Loss 0.30076906
Epoch [2]: Loss 0.28550825
Epoch [2]: Loss 0.2774137
Validation: Loss 0.2533846 Accuracy 1.0
Validation: Loss 0.25061357 Accuracy 1.0
Epoch [3]: Loss 0.26135722
Epoch [3]: Loss 0.24415436
Epoch [3]: Loss 0.23032708
Epoch [3]: Loss 0.22208829
Epoch [3]: Loss 0.20949815
Epoch [3]: Loss 0.20015056
Epoch [3]: Loss 0.18618253
Validation: Loss 0.17866787 Accuracy 1.0
Validation: Loss 0.17752072 Accuracy 1.0
Epoch [4]: Loss 0.17985228
Epoch [4]: Loss 0.17115924
Epoch [4]: Loss 0.16337122
Epoch [4]: Loss 0.15548234
Epoch [4]: Loss 0.14899094
Epoch [4]: Loss 0.14074819
Epoch [4]: Loss 0.13699809
Validation: Loss 0.12782894 Accuracy 1.0
Validation: Loss 0.12708837 Accuracy 1.0
Epoch [5]: Loss 0.12914
Epoch [5]: Loss 0.12342137
Epoch [5]: Loss 0.1174591
Epoch [5]: Loss 0.11262639
Epoch [5]: Loss 0.10693622
Epoch [5]: Loss 0.10238779
Epoch [5]: Loss 0.095023975
Validation: Loss 0.09262835 Accuracy 1.0
Validation: Loss 0.09189776 Accuracy 1.0
Epoch [6]: Loss 0.09456956
Epoch [6]: Loss 0.08908226
Epoch [6]: Loss 0.08551159
Epoch [6]: Loss 0.083542846
Epoch [6]: Loss 0.07824499
Epoch [6]: Loss 0.07550718
Epoch [6]: Loss 0.069536075
Validation: Loss 0.06756733 Accuracy 1.0
Validation: Loss 0.06666996 Accuracy 1.0
Epoch [7]: Loss 0.070025146
Epoch [7]: Loss 0.06577993
Epoch [7]: Loss 0.0638792
Epoch [7]: Loss 0.06007722
Epoch [7]: Loss 0.058916517
Epoch [7]: Loss 0.056527
Epoch [7]: Loss 0.055039197
Validation: Loss 0.049828634 Accuracy 1.0
Validation: Loss 0.048877507 Accuracy 1.0
Epoch [8]: Loss 0.051252667
Epoch [8]: Loss 0.050525658
Epoch [8]: Loss 0.048194516
Epoch [8]: Loss 0.045601007
Epoch [8]: Loss 0.044168867
Epoch [8]: Loss 0.041488305
Epoch [8]: Loss 0.04241644
Validation: Loss 0.037148625 Accuracy 1.0
Validation: Loss 0.036250744 Accuracy 1.0
Epoch [9]: Loss 0.039104506
Epoch [9]: Loss 0.036284316
Epoch [9]: Loss 0.037037857
Epoch [9]: Loss 0.034446135
Epoch [9]: Loss 0.03247141
Epoch [9]: Loss 0.034019932
Epoch [9]: Loss 0.031409588
Validation: Loss 0.028168112 Accuracy 1.0
Validation: Loss 0.027345307 Accuracy 1.0
Epoch [10]: Loss 0.030661054
Epoch [10]: Loss 0.029295746
Epoch [10]: Loss 0.028844714
Epoch [10]: Loss 0.025228765
Epoch [10]: Loss 0.025671711
Epoch [10]: Loss 0.025505602
Epoch [10]: Loss 0.024544626
Validation: Loss 0.022044972 Accuracy 1.0
Validation: Loss 0.021316608 Accuracy 1.0
Epoch [11]: Loss 0.023833783
Epoch [11]: Loss 0.022684032
Epoch [11]: Loss 0.02297335
Epoch [11]: Loss 0.021807164
Epoch [11]: Loss 0.020623289
Epoch [11]: Loss 0.019909402
Epoch [11]: Loss 0.01994735
Validation: Loss 0.017891068 Accuracy 1.0
Validation: Loss 0.01725432 Accuracy 1.0
Epoch [12]: Loss 0.018950945
Epoch [12]: Loss 0.018840132
Epoch [12]: Loss 0.01925065
Epoch [12]: Loss 0.017439095
Epoch [12]: Loss 0.017116357
Epoch [12]: Loss 0.017091103
Epoch [12]: Loss 0.016754571
Validation: Loss 0.015016966 Accuracy 1.0
Validation: Loss 0.0144599015 Accuracy 1.0
Epoch [13]: Loss 0.016343242
Epoch [13]: Loss 0.016224064
Epoch [13]: Loss 0.0155079095
Epoch [13]: Loss 0.015357371
Epoch [13]: Loss 0.015736738
Epoch [13]: Loss 0.013841201
Epoch [13]: Loss 0.012142584
Validation: Loss 0.01296171 Accuracy 1.0
Validation: Loss 0.012468269 Accuracy 1.0
Epoch [14]: Loss 0.014052439
Epoch [14]: Loss 0.014569383
Epoch [14]: Loss 0.012918631
Epoch [14]: Loss 0.013404069
Epoch [14]: Loss 0.012558143
Epoch [14]: Loss 0.012912078
Epoch [14]: Loss 0.013146299
Validation: Loss 0.0114261815 Accuracy 1.0
Validation: Loss 0.010978804 Accuracy 1.0
Epoch [15]: Loss 0.011647966
Epoch [15]: Loss 0.012647331
Epoch [15]: Loss 0.012600974
Epoch [15]: Loss 0.011439533
Epoch [15]: Loss 0.012460645
Epoch [15]: Loss 0.011002184
Epoch [15]: Loss 0.010119411
Validation: Loss 0.0102224 Accuracy 1.0
Validation: Loss 0.009815964 Accuracy 1.0
Epoch [16]: Loss 0.010909705
Epoch [16]: Loss 0.011749736
Epoch [16]: Loss 0.010810578
Epoch [16]: Loss 0.010074029
Epoch [16]: Loss 0.010436619
Epoch [16]: Loss 0.01019301
Epoch [16]: Loss 0.010841265
Validation: Loss 0.009246437 Accuracy 1.0
Validation: Loss 0.008870984 Accuracy 1.0
Epoch [17]: Loss 0.009876712
Epoch [17]: Loss 0.010232468
Epoch [17]: Loss 0.010510688
Epoch [17]: Loss 0.0096674245
Epoch [17]: Loss 0.009246782
Epoch [17]: Loss 0.009310809
Epoch [17]: Loss 0.007776724
Validation: Loss 0.00843331 Accuracy 1.0
Validation: Loss 0.00808557 Accuracy 1.0
Epoch [18]: Loss 0.009405469
Epoch [18]: Loss 0.009561165
Epoch [18]: Loss 0.008702648
Epoch [18]: Loss 0.008959407
Epoch [18]: Loss 0.0080647655
Epoch [18]: Loss 0.008931208
Epoch [18]: Loss 0.008100244
Validation: Loss 0.0077453176 Accuracy 1.0
Validation: Loss 0.0074227867 Accuracy 1.0
Epoch [19]: Loss 0.008524146
Epoch [19]: Loss 0.008673817
Epoch [19]: Loss 0.008274006
Epoch [19]: Loss 0.007752863
Epoch [19]: Loss 0.008231993
Epoch [19]: Loss 0.007938891
Epoch [19]: Loss 0.0075147036
Validation: Loss 0.0071525904 Accuracy 1.0
Validation: Loss 0.0068492335 Accuracy 1.0
Epoch [20]: Loss 0.007939931
Epoch [20]: Loss 0.0077575548
Epoch [20]: Loss 0.007832317
Epoch [20]: Loss 0.0077150934
Epoch [20]: Loss 0.007145924
Epoch [20]: Loss 0.007419157
Epoch [20]: Loss 0.0067237904
Validation: Loss 0.0066367947 Accuracy 1.0
Validation: Loss 0.0063526677 Accuracy 1.0
Epoch [21]: Loss 0.0072976486
Epoch [21]: Loss 0.0069842986
Epoch [21]: Loss 0.007581325
Epoch [21]: Loss 0.0071216514
Epoch [21]: Loss 0.0069266534
Epoch [21]: Loss 0.0066482928
Epoch [21]: Loss 0.0064652828
Validation: Loss 0.006184045 Accuracy 1.0
Validation: Loss 0.005916884 Accuracy 1.0
Epoch [22]: Loss 0.007132771
Epoch [22]: Loss 0.006883101
Epoch [22]: Loss 0.0065401783
Epoch [22]: Loss 0.006368112
Epoch [22]: Loss 0.006334458
Epoch [22]: Loss 0.0065234248
Epoch [22]: Loss 0.0058823684
Validation: Loss 0.0057827346 Accuracy 1.0
Validation: Loss 0.005530903 Accuracy 1.0
Epoch [23]: Loss 0.0059599327
Epoch [23]: Loss 0.0064247437
Epoch [23]: Loss 0.006236594
Epoch [23]: Loss 0.006032017
Epoch [23]: Loss 0.006126586
Epoch [23]: Loss 0.006336821
Epoch [23]: Loss 0.0060630157
Validation: Loss 0.0054259133 Accuracy 1.0
Validation: Loss 0.005186828 Accuracy 1.0
Epoch [24]: Loss 0.006013855
Epoch [24]: Loss 0.0060069123
Epoch [24]: Loss 0.0058390833
Epoch [24]: Loss 0.0058100126
Epoch [24]: Loss 0.005874091
Epoch [24]: Loss 0.0053072134
Epoch [24]: Loss 0.005864639
Validation: Loss 0.0051035127 Accuracy 1.0
Validation: Loss 0.0048780153 Accuracy 1.0
Epoch [25]: Loss 0.0056182873
Epoch [25]: Loss 0.005437928
Epoch [25]: Loss 0.0058011757
Epoch [25]: Loss 0.0052488605
Epoch [25]: Loss 0.0052916394
Epoch [25]: Loss 0.005459973
Epoch [25]: Loss 0.0053728707
Validation: Loss 0.0048131603 Accuracy 1.0
Validation: Loss 0.004601411 Accuracy 1.0</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../Basics/main/">« Julia &amp; Lux for the Uninitiated</a><a class="docs-footer-nextpage" href="../../../intermediate/NeuralODE/main/">MNIST NeuralODE Classification »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.17 on <span class="colophon-date" title="Wednesday 18 May 2022 04:53">Wednesday 18 May 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

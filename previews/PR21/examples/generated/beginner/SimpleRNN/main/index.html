<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training a Simple LSTM · Lux</title><script data-outdated-warner src="../../../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../../../assets/documenter.js"></script><script src="../../../../../siteinfo.js"></script><script src="../../../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../../../assets/themeswap.js"></script><link href="../../../../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../../../../">Lux</a></span></div><form class="docs-search" action="../../../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../../../">Lux: Explicitly Parameterized Neural Networks</a></li><li><span class="tocitem">Introduction</span><ul><li><a class="tocitem" href="../../../../../introduction/overview/">All about Lux</a></li><li><a class="tocitem" href="../../../../../introduction/ecosystem/">Ecosystem</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox" checked/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Beginner</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../Basics/main/">Julia &amp; Lux for the Uninitiated</a></li><li class="is-active"><a class="tocitem" href>Training a Simple LSTM</a><ul class="internal"><li><a class="tocitem" href="#Package-Imports"><span>Package Imports</span></a></li><li><a class="tocitem" href="#Dataset"><span>Dataset</span></a></li><li><a class="tocitem" href="#Creating-a-Classifier"><span>Creating a Classifier</span></a></li><li><a class="tocitem" href="#Defining-Accuracy,-Loss-and-Optimiser"><span>Defining Accuracy, Loss and Optimiser</span></a></li><li><a class="tocitem" href="#Training-the-Model"><span>Training the Model</span></a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Intermediate</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../intermediate/NeuralODE/main/">MNIST NeuralODE Classification</a></li><li><a class="tocitem" href="../../../intermediate/BayesianNN/main/">Bayesian Neural Network</a></li></ul></li><li><span class="tocitem">Advanced</span></li><li><a class="tocitem" href="../../../../">Additional Examples</a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../../../../../api/layers/">Layers</a></li><li><a class="tocitem" href="../../../../../api/functional/">Functional</a></li><li><a class="tocitem" href="../../../../../api/core/">Core</a></li><li><a class="tocitem" href="../../../../../api/utilities/">Utilities</a></li></ul></li><li><span class="tocitem">Design Docs</span><ul><li><a class="tocitem" href="../../../../../design/recurrent/">Recurrent Neural Networks</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li><a class="is-disabled">Beginner</a></li><li class="is-active"><a href>Training a Simple LSTM</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Training a Simple LSTM</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/avik-pal/Lux.jl/blob/main/examples/SimpleRNN/main.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Training-a-Simple-LSTM"><a class="docs-heading-anchor" href="#Training-a-Simple-LSTM">Training a Simple LSTM</a><a id="Training-a-Simple-LSTM-1"></a><a class="docs-heading-anchor-permalink" href="#Training-a-Simple-LSTM" title="Permalink"></a></h1><p>In this tutorial we will go over using a recurrent neural network to classify clockwise and anticlockwise spirals. By the end of this tutorial you will be able to:</p><ol><li>Create custom Lux models</li><li>Become familiar with the Lux recurrent neural network API</li><li>Training using Optimisers.jl and Zygote.jl</li></ol><h2 id="Package-Imports"><a class="docs-heading-anchor" href="#Package-Imports">Package Imports</a><a id="Package-Imports-1"></a><a class="docs-heading-anchor-permalink" href="#Package-Imports" title="Permalink"></a></h2><pre><code class="language-julia hljs">using Lux
using MLUtils, Optimisers, Zygote, NNlib, Random, Statistics</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">  Activating project at `~/work/Lux.jl/Lux.jl/examples`</code></pre><h2 id="Dataset"><a class="docs-heading-anchor" href="#Dataset">Dataset</a><a id="Dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Dataset" title="Permalink"></a></h2><p>We will use MLUtils to generate 500 (noisy) clockwise and 500 (noisy) anticlockwise spirals. Using this data we will create a <code>MLUtils.DataLoader</code>. Our dataloader will give us sequences of size 2 × seq<em>len × batch</em>size and we need to predict a binary value whether the sequence is clockwise or anticlockwise</p><pre><code class="language-julia hljs">function get_dataloaders(; dataset_size=1000, sequence_length=50)
    # Create the spirals
    data = [MLUtils.Datasets.make_spiral(sequence_length) for _ in 1:dataset_size]
    # Get the labels
    labels = vcat(repeat([0.0f0], dataset_size ÷ 2), repeat([1.0f0], dataset_size ÷ 2))
    clockwise_spirals = [reshape(d[1][:, 1:sequence_length], :, sequence_length, 1) for d in data[1:(dataset_size ÷ 2)]]
    anticlockwise_spirals = [
        reshape(d[1][:, (sequence_length + 1):end], :, sequence_length, 1) for d in data[((dataset_size ÷ 2) + 1):end]
    ]
    x_data = Float32.(cat(clockwise_spirals..., anticlockwise_spirals...; dims=3))
    # Split the dataset
    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)
    # Create DataLoaders
    return (
        # Use DataLoader to automatically minibatch and shuffle the data
        DataLoader(collect.((x_train, y_train)); batchsize=128, shuffle=true),
        # Don&#39;t shuffle the validation data
        DataLoader(collect.((x_val, y_val)); batchsize=128, shuffle=false),
    )
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">get_dataloaders (generic function with 1 method)</code></pre><h2 id="Creating-a-Classifier"><a class="docs-heading-anchor" href="#Creating-a-Classifier">Creating a Classifier</a><a id="Creating-a-Classifier-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-a-Classifier" title="Permalink"></a></h2><p>We will be extending the <code>Lux.AbstractExplicitContainerLayer</code> type for our custom model since it will contain a lstm block and a classifier head.</p><p>We pass the fieldnames <code>lstm_cell</code> and <code>classifier</code> to the type to ensure that the parameters and states are automatically populated and we don&#39;t have to define <a href="../../../../../api/core/#Lux.initialparameters"><code>Lux.initialparameters</code></a> and <a href="../../../../../api/core/#Lux.initialstates"><code>Lux.initialstates</code></a>.</p><pre><code class="language-julia hljs">struct SpiralClassifier{L,C} &lt;: Lux.AbstractExplicitContainerLayer{(:lstm_cell, :classifier)}
    lstm_cell::L
    classifier::C
end</code></pre><p>We won&#39;t define the model from scratch but rather use the <a href="../../../../../api/layers/#Lux.LSTMCell"><code>Lux.LSTMCell</code></a> and <a href="../../../../../api/layers/#Lux.Dense"><code>Lux.Dense</code></a></p><pre><code class="language-julia hljs">function SpiralClassifier(in_dims, hidden_dims, out_dims)
    return SpiralClassifier(LSTMCell(in_dims =&gt; hidden_dims), Dense(hidden_dims =&gt; out_dims, sigmoid))
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Main.SpiralClassifier</code></pre><p>Now we need to define the behavior of the Classifier when it is invoked</p><pre><code class="language-julia hljs">function (s::SpiralClassifier)(x::AbstractArray{T,3}, ps::NamedTuple, st::NamedTuple) where {T}
    # First we will have to run the sequence through the LSTM Cell
    # The first call to LSTM Cell will create the initial hidden state
    # See that the parameters and states are automatically populated into a field called `lstm_cell`
    # We use `view(x, :, 1, :)` to get the first element in the sequence without copying it
    (h, c), st_lstm = s.lstm_cell(view(x, :, 1, :), ps.lstm_cell, st.lstm_cell)
    # Now that we have the hidden state we will pass the input and hidden state jointly
    for i in 1:size(x, 2)
        (h, c), st_lstm = s.lstm_cell((view(x, :, i, :), h, c), ps.lstm_cell, st_lstm)
    end
    # After running through the sequence we will pass the output through the classifier
    y, st_classifier = s.classifier(h, ps.classifier, st.classifier)
    # Finally remember to create the updated state
    st = merge(st, (classifier=st_classifier, lstm_cell=st_lstm))
    return vec(y), st
end</code></pre><h2 id="Defining-Accuracy,-Loss-and-Optimiser"><a class="docs-heading-anchor" href="#Defining-Accuracy,-Loss-and-Optimiser">Defining Accuracy, Loss and Optimiser</a><a id="Defining-Accuracy,-Loss-and-Optimiser-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-Accuracy,-Loss-and-Optimiser" title="Permalink"></a></h2><p>Now let&#39;s define the binarycrossentropy loss. Typically it is recommended to use <code>logitbinarycrossentropy</code> since it is more numerically stable, but for the sake of simplicity we will use <code>binarycrossentropy</code></p><pre><code class="language-julia hljs">function xlogy(x, y)
    result = x * log(y)
    return ifelse(iszero(x), zero(result), result)
end

function binarycrossentropy(y_pred, y_true)
    y_pred = y_pred .+ eps(eltype(y_pred))
    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))
end

function compute_loss(x, y, model, ps, st)
    y_pred, st = model(x, ps, st)
    return binarycrossentropy(y_pred, y), y_pred, st
end

matches(y_pred, y_true) = sum((y_pred .&gt; 0.5) .== y_true)
accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">accuracy (generic function with 1 method)</code></pre><p>Finally lets create an optimiser given the model parameters</p><pre><code class="language-julia hljs">function create_optimiser(ps)
    opt = Optimisers.ADAM(0.01f0)
    return Optimisers.setup(opt, ps)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">create_optimiser (generic function with 1 method)</code></pre><h2 id="Training-the-Model"><a class="docs-heading-anchor" href="#Training-the-Model">Training the Model</a><a id="Training-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Training-the-Model" title="Permalink"></a></h2><pre><code class="language-julia hljs">function main()
    # Get the dataloaders
    (train_loader, val_loader) = get_dataloaders()

    # Create the model
    model = SpiralClassifier(2, 8, 1)
    rng = Random.default_rng()
    Random.seed!(rng, 0)
    ps, st = Lux.setup(rng, model)

    # Create the optimiser
    opt_state = create_optimiser(ps)

    for epoch in 1:25
        # Train the model
        for (x, y) in train_loader
            (loss, y_pred, st), back = pullback(p -&gt; compute_loss(x, y, model, p, st), ps)
            gs = back((one(loss), nothing, nothing))[1]
            opt_state, ps = Optimisers.update(opt_state, ps, gs)

            println(&quot;Epoch [$epoch]: Loss $loss&quot;)
        end

        # Validate the model
        st_ = Lux.testmode(st)
        for (x, y) in val_loader
            (loss, y_pred, st_) = compute_loss(x, y, model, ps, st_)
            acc = accuracy(y_pred, y)
            println(&quot;Validation: Loss $loss Accuracy $acc&quot;)
        end
    end
end

main()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch [1]: Loss 0.56184506
Epoch [1]: Loss 0.5091104
Epoch [1]: Loss 0.4769262
Epoch [1]: Loss 0.45212954
Epoch [1]: Loss 0.42452693
Epoch [1]: Loss 0.40331286
Epoch [1]: Loss 0.39020786
Validation: Loss 0.36477584 Accuracy 1.0
Validation: Loss 0.36574173 Accuracy 1.0
Epoch [2]: Loss 0.36323157
Epoch [2]: Loss 0.35150355
Epoch [2]: Loss 0.33425036
Epoch [2]: Loss 0.31941998
Epoch [2]: Loss 0.29716876
Epoch [2]: Loss 0.2897184
Epoch [2]: Loss 0.26194242
Validation: Loss 0.25491902 Accuracy 1.0
Validation: Loss 0.25583178 Accuracy 1.0
Epoch [3]: Loss 0.25474438
Epoch [3]: Loss 0.24796799
Epoch [3]: Loss 0.23192818
Epoch [3]: Loss 0.21789624
Epoch [3]: Loss 0.20733275
Epoch [3]: Loss 0.19965245
Epoch [3]: Loss 0.18796498
Validation: Loss 0.17779095 Accuracy 1.0
Validation: Loss 0.1783438 Accuracy 1.0
Epoch [4]: Loss 0.17722605
Epoch [4]: Loss 0.16986424
Epoch [4]: Loss 0.16297354
Epoch [4]: Loss 0.1545144
Epoch [4]: Loss 0.14652975
Epoch [4]: Loss 0.14033093
Epoch [4]: Loss 0.13496599
Validation: Loss 0.12643866 Accuracy 1.0
Validation: Loss 0.1267615 Accuracy 1.0
Epoch [5]: Loss 0.12745416
Epoch [5]: Loss 0.12264167
Epoch [5]: Loss 0.11525739
Epoch [5]: Loss 0.11118184
Epoch [5]: Loss 0.104125515
Epoch [5]: Loss 0.10128274
Epoch [5]: Loss 0.096129656
Validation: Loss 0.09157555 Accuracy 1.0
Validation: Loss 0.09179374 Accuracy 1.0
Epoch [6]: Loss 0.092241295
Epoch [6]: Loss 0.08892604
Epoch [6]: Loss 0.08470659
Epoch [6]: Loss 0.08033473
Epoch [6]: Loss 0.07707871
Epoch [6]: Loss 0.07306853
Epoch [6]: Loss 0.072609395
Validation: Loss 0.06723485 Accuracy 1.0
Validation: Loss 0.06741824 Accuracy 1.0
Epoch [7]: Loss 0.067979574
Epoch [7]: Loss 0.06614789
Epoch [7]: Loss 0.06223471
Epoch [7]: Loss 0.058731847
Epoch [7]: Loss 0.05695976
Epoch [7]: Loss 0.0550164
Epoch [7]: Loss 0.053227164
Validation: Loss 0.04994098 Accuracy 1.0
Validation: Loss 0.05009258 Accuracy 1.0
Epoch [8]: Loss 0.050887782
Epoch [8]: Loss 0.04922581
Epoch [8]: Loss 0.04673785
Epoch [8]: Loss 0.044734225
Epoch [8]: Loss 0.04179838
Epoch [8]: Loss 0.04049973
Epoch [8]: Loss 0.041277062
Validation: Loss 0.037427876 Accuracy 1.0
Validation: Loss 0.03755267 Accuracy 1.0
Epoch [9]: Loss 0.038331885
Epoch [9]: Loss 0.03665256
Epoch [9]: Loss 0.034699064
Epoch [9]: Loss 0.033661336
Epoch [9]: Loss 0.031852692
Epoch [9]: Loss 0.03101914
Epoch [9]: Loss 0.033494268
Validation: Loss 0.028493172 Accuracy 1.0
Validation: Loss 0.028602414 Accuracy 1.0
Epoch [10]: Loss 0.028832456
Epoch [10]: Loss 0.027263785
Epoch [10]: Loss 0.027288886
Epoch [10]: Loss 0.025116341
Epoch [10]: Loss 0.02565574
Epoch [10]: Loss 0.025375443
Epoch [10]: Loss 0.02339391
Validation: Loss 0.022354437 Accuracy 1.0
Validation: Loss 0.022451619 Accuracy 1.0
Epoch [11]: Loss 0.022502083
Epoch [11]: Loss 0.022008287
Epoch [11]: Loss 0.021307208
Epoch [11]: Loss 0.02020977
Epoch [11]: Loss 0.020499296
Epoch [11]: Loss 0.020413283
Epoch [11]: Loss 0.019043712
Validation: Loss 0.01817184 Accuracy 1.0
Validation: Loss 0.018257612 Accuracy 1.0
Epoch [12]: Loss 0.017450754
Epoch [12]: Loss 0.01824451
Epoch [12]: Loss 0.018222852
Epoch [12]: Loss 0.017215878
Epoch [12]: Loss 0.017544705
Epoch [12]: Loss 0.01601138
Epoch [12]: Loss 0.015409979
Validation: Loss 0.015267609 Accuracy 1.0
Validation: Loss 0.015344298 Accuracy 1.0
Epoch [13]: Loss 0.015423654
Epoch [13]: Loss 0.014730098
Epoch [13]: Loss 0.015868759
Epoch [13]: Loss 0.014197309
Epoch [13]: Loss 0.013928015
Epoch [13]: Loss 0.014686252
Epoch [13]: Loss 0.013589441
Validation: Loss 0.013185917 Accuracy 1.0
Validation: Loss 0.013256085 Accuracy 1.0
Epoch [14]: Loss 0.013869268
Epoch [14]: Loss 0.013816841
Epoch [14]: Loss 0.013190429
Epoch [14]: Loss 0.012787113
Epoch [14]: Loss 0.011981457
Epoch [14]: Loss 0.012001349
Epoch [14]: Loss 0.011083124
Validation: Loss 0.011621326 Accuracy 1.0
Validation: Loss 0.011685252 Accuracy 1.0
Epoch [15]: Loss 0.0118183335
Epoch [15]: Loss 0.011009715
Epoch [15]: Loss 0.011979973
Epoch [15]: Loss 0.011340416
Epoch [15]: Loss 0.011594266
Epoch [15]: Loss 0.010603523
Epoch [15]: Loss 0.011701513
Validation: Loss 0.01040509 Accuracy 1.0
Validation: Loss 0.01046518 Accuracy 1.0
Epoch [16]: Loss 0.011031338
Epoch [16]: Loss 0.010535043
Epoch [16]: Loss 0.010580553
Epoch [16]: Loss 0.009506216
Epoch [16]: Loss 0.01023974
Epoch [16]: Loss 0.010204012
Epoch [16]: Loss 0.008144121
Validation: Loss 0.009416061 Accuracy 1.0
Validation: Loss 0.009472166 Accuracy 1.0
Epoch [17]: Loss 0.009548527
Epoch [17]: Loss 0.009219671
Epoch [17]: Loss 0.009979402
Epoch [17]: Loss 0.009545343
Epoch [17]: Loss 0.0086764535
Epoch [17]: Loss 0.00913024
Epoch [17]: Loss 0.008603372
Validation: Loss 0.008598277 Accuracy 1.0
Validation: Loss 0.008651681 Accuracy 1.0
Epoch [18]: Loss 0.009005272
Epoch [18]: Loss 0.008610688
Epoch [18]: Loss 0.009138794
Epoch [18]: Loss 0.008402173
Epoch [18]: Loss 0.00807841
Epoch [18]: Loss 0.008371955
Epoch [18]: Loss 0.007010102
Validation: Loss 0.007903755 Accuracy 1.0
Validation: Loss 0.00795418 Accuracy 1.0
Epoch [19]: Loss 0.0083005335
Epoch [19]: Loss 0.0075390865
Epoch [19]: Loss 0.008032212
Epoch [19]: Loss 0.008240352
Epoch [19]: Loss 0.008193651
Epoch [19]: Loss 0.0069793668
Epoch [19]: Loss 0.007534238
Validation: Loss 0.0073071 Accuracy 1.0
Validation: Loss 0.007355478 Accuracy 1.0
Epoch [20]: Loss 0.007888654
Epoch [20]: Loss 0.0071723023
Epoch [20]: Loss 0.007700012
Epoch [20]: Loss 0.007005102
Epoch [20]: Loss 0.007272492
Epoch [20]: Loss 0.006764121
Epoch [20]: Loss 0.007003755
Validation: Loss 0.006785362 Accuracy 1.0
Validation: Loss 0.0068309773 Accuracy 1.0
Epoch [21]: Loss 0.006767337
Epoch [21]: Loss 0.0067551634
Epoch [21]: Loss 0.006930955
Epoch [21]: Loss 0.007161554
Epoch [21]: Loss 0.0067115566
Epoch [21]: Loss 0.0063638235
Epoch [21]: Loss 0.0067085563
Validation: Loss 0.006326427 Accuracy 1.0
Validation: Loss 0.006370155 Accuracy 1.0
Epoch [22]: Loss 0.0058209207
Epoch [22]: Loss 0.0065392684
Epoch [22]: Loss 0.006236794
Epoch [22]: Loss 0.0065961275
Epoch [22]: Loss 0.0065923617
Epoch [22]: Loss 0.0064092395
Epoch [22]: Loss 0.005398771
Validation: Loss 0.0059192018 Accuracy 1.0
Validation: Loss 0.005960392 Accuracy 1.0
Epoch [23]: Loss 0.0060033384
Epoch [23]: Loss 0.005953591
Epoch [23]: Loss 0.005682975
Epoch [23]: Loss 0.005878116
Epoch [23]: Loss 0.0060250065
Epoch [23]: Loss 0.0058577345
Epoch [23]: Loss 0.006603377
Validation: Loss 0.0055560693 Accuracy 1.0
Validation: Loss 0.005595656 Accuracy 1.0
Epoch [24]: Loss 0.0056492426
Epoch [24]: Loss 0.005342161
Epoch [24]: Loss 0.0058127455
Epoch [24]: Loss 0.0056968224
Epoch [24]: Loss 0.005472269
Epoch [24]: Loss 0.005503855
Epoch [24]: Loss 0.005373602
Validation: Loss 0.0052267676 Accuracy 1.0
Validation: Loss 0.005264009 Accuracy 1.0
Epoch [25]: Loss 0.0055288537
Epoch [25]: Loss 0.0053666523
Epoch [25]: Loss 0.005099475
Epoch [25]: Loss 0.005167342
Epoch [25]: Loss 0.0053488184
Epoch [25]: Loss 0.005016393
Epoch [25]: Loss 0.0050757234
Validation: Loss 0.0049298904 Accuracy 1.0
Validation: Loss 0.0049653566 Accuracy 1.0</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../Basics/main/">« Julia &amp; Lux for the Uninitiated</a><a class="docs-footer-nextpage" href="../../../intermediate/NeuralODE/main/">MNIST NeuralODE Classification »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.17 on <span class="colophon-date" title="Wednesday 18 May 2022 05:19">Wednesday 18 May 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
